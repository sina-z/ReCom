# Data Directory

This directory stores all datasets used in the ReCom project.

## ğŸ“ Structure

```
data/
â”œâ”€â”€ raw/          # Original, immutable datasets
â”œâ”€â”€ processed/    # Cleaned and transformed data
â””â”€â”€ README.md     # This file
```

## ğŸ“‹ Guidelines

### `raw/` Directory
**Purpose**: Store original datasets exactly as downloaded/received

**Rules**:
- âœ… Never modify files here
- âœ… Keep original format (CSV, JSON, etc.)
- âœ… Document source and download date
- âŒ Don't commit to git (see .gitignore)

**Example**:
```
raw/
â”œâ”€â”€ lastfm_dataset.csv
â”œâ”€â”€ user_data_2026_02_07.json
â””â”€â”€ README.md  # Document sources here
```

### `processed/` Directory
**Purpose**: Store cleaned, transformed, ready-to-use data

**Rules**:
- âœ… Include preprocessing scripts in `src/data/`
- âœ… Use consistent naming (e.g., `train_2026_02_07.csv`)
- âœ… Document transformations applied
- âŒ Don't commit to git (see .gitignore)

**Example**:
```
processed/
â”œâ”€â”€ train_interactions.csv
â”œâ”€â”€ test_interactions.csv
â”œâ”€â”€ user_features.parquet
â””â”€â”€ README.md  # Document processing steps
```

## ğŸš€ Phase 0 - Data Sources

**We will decide on ONE of these sources**:

### Option 1: Last.fm Dataset
- **Size**: ~360K users, ~160K artists
- **Source**: http://www.dtic.upf.edu/~ocelma/MusicRecommendationDataset/
- **Format**: Tab-separated values (TSV)
- **Pros**: Real music data, rich interactions
- **Cons**: Larger download

### Option 2: Million Song Dataset (Subset)
- **Size**: 10,000 songs subset
- **Source**: http://millionsongdataset.com/
- **Format**: HDF5 / CSV
- **Pros**: Well-documented, academic standard
- **Cons**: Requires more preprocessing

### Option 3: Synthetic Dataset
- **Size**: Configurable (we generate it)
- **Source**: Generated by us using Python
- **Format**: CSV / Pandas DataFrame
- **Pros**: Full control, fast start, easy debugging
- **Cons**: Not real user behavior patterns

## ğŸ“ Data Documentation Template

When you add a dataset, create a README in the appropriate subfolder:

```markdown
# Dataset Name

**Source**: [URL or description]
**Downloaded**: YYYY-MM-DD
**Size**: X MB / X rows
**Format**: CSV/JSON/Parquet
**License**: [If applicable]

## Columns
- `column_name`: Description, data type, example values

## Notes
- Any quirks, missing values, or important observations
```

## ğŸ”’ Important Notes

1. **Git Ignore**: Data files are NOT committed to git
   - Datasets can be huge (GBs)
   - Store in cloud (Google Drive, S3) if sharing
   - Document download instructions instead

2. **Reproducibility**: Always document:
   - Where data came from
   - When it was downloaded
   - Any manual steps taken
   - Preprocessing scripts (in `src/data/`)

3. **Privacy**: If using real user data:
   - Ensure proper anonymization
   - Follow data usage terms
   - Don't expose PII (personally identifiable information)

---

**Next Steps**: Once we choose a dataset in Phase 0, we'll update this README with specific details.
